---
title: "Final Project"
author: "The Extrapolats"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
---


```{r init, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(echo = T, warning = F, results = "show", message = F)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times

```

# Marriage Proposal Dataset Analysis - Code & Technical Analysis

## STEP 1: Loading the Dataset

```{r}
# Reading the dataset
proposal_df = read.csv("marriage_proposal.csv")
```


```{r}
# Structure of the dataset
str(proposal_df)
```
## STEP 2: Cleaning the dataset

```{r}
# Check for empty and NA values 
empty_values <- sapply(proposal_df, function(x) sum(x == "", na.rm = TRUE))
na_values <- sapply(proposal_df, function(x) sum(is.na(x)))
print("Empty Values in Each Column:")
print(empty_values)
print("NA Values in Each Column:")
print(na_values)
```

```{r}
# Converting required 'int' columns into 'factor'
proposal_df$RomanticGestureScore <- as.factor(proposal_df$RomanticGestureScore)
proposal_df$CompatibilityScore <- as.factor(proposal_df$CompatibilityScore)
proposal_df$CommunicationScore <- as.factor(proposal_df$CommunicationScore)
proposal_df$Response <- as.factor(proposal_df$Response)
```

```{r}
print("Summary of cleaned data")
summary(proposal_df)
```
## STEP 3: Exploratory Data Analysis

### Loading necessary libraries

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(psych)
library(tidyverse) 
library(ggplot2) 
library(viridis) 
library(RColorBrewer) 
library(ggmosaic)

library(gridExtra)
library(caret)
library(pROC)
library(rpart)
library(rpart.plot)
library(randomForest)
```

### Distribution of the Numeric variables

Let’s take a look at descriptive stats of Numeric variables.
```{r}
# Descriptive Statistics
# Numeric variables
describe(proposal_df %>% select(Age, Height, Income, DistanceKM))
```

Graphical Representations of Integer variables.

```{r}
# Histogram of age

ggplot(proposal_df, aes(x = Age, fill = Age)) + geom_histogram(binwidth = 5, fill = "lightpink", color = "black") + labs(title = "Age Distribution", x = "Age", y = "Frequency") + theme_minimal()
```

```{r, warning=FALSE}
# Frequency polygon for Height
ggplot(proposal_df, aes(x = Height)) + 
  geom_freqpoly(binwidth = 5, color = "grey", size = 1.2) + 
  labs(title = "Height Distribution", x = "Height (cm)", y = "Frequency") + 
  theme_minimal()

```

```{r}
#proposal_df <- outlierKD2(proposal_df, DistanceKM, rm = TRUE, boxplt = TRUE, histogram = FALSE, qqplt = TRUE)
```

```{r}
ggplot(proposal_df, aes(x = cut(Income, 
                                breaks = c(5000, 20000, 30000, 40000, 50000), 
                                labels = c("Low Income", "Medium Income", "High Income", "Very High Income"), 
                                include.lowest = TRUE))) + 
  geom_bar(fill = "steelblue", color = "black") + 
  labs(title = "Population Distribution by Income Category", 
       x = "Income Category", 
       y = "Frequency") + 
  theme_minimal()

```
```{r}
# Boxplot for Distance
ggplot(proposal_df, aes(y = DistanceKM)) + geom_boxplot(fill = "lightyellow", color = "black") + labs(title = "Distance (KM) Boxplot", y = "Distance (KM)") + theme_minimal()
```

Graphical Representations of Factorial variables.

```{r, warning=FALSE}
# Pie chart for Response variable
ggplot(proposal_df, aes(x = "", fill = Response)) + geom_bar(width = 1, stat = "count", color = "black") + coord_polar(theta = "y") + geom_text(aes(label = scales::percent(..count../sum(..count..))), position = position_stack(vjust = 0.5), stat = "count") + scale_fill_manual(values = c("0" = "red", "1" = "green"), labels = c("Rejected", "Accepted")) + labs(title = "Proposal Response Distribution", fill = "Response") + theme_void() + theme(plot.title = element_text(hjust = 0.5, size = 16))
```

```{r}
# bar plot for CommunicationScore
p1 <- ggplot(proposal_df, aes(x = as.factor(CommunicationScore))) + geom_bar(fill = "blue", color = "black") + labs(title = "Communication Score Distribution", x = "Communication Score", y = "Frequency") + theme_minimal()

# bar plot for CompatibilityScore
p2 <- ggplot(proposal_df, aes(x = as.factor(CompatibilityScore))) + geom_bar(fill = "green", color = "black") + labs(title = "Compatibility Score Distribution", x = "Compatibility Score", y = "Frequency") + theme_minimal()

grid.arrange(p1, p2, ncol = 2)
```


## STEP 4: SMART Questions

### 4.1: Is there a statistically significant difference in the Response variable (Proposal Accepted vs Rejected) based on the Income of the individual?
```{r}
ggplot(proposal_df, aes(x = cut(Income, breaks = c(5000, 20000, 30000, 40000, 50000), labels = c("Low Income", "Medium Income", "High Income", "Very High Income"), include.lowest = TRUE), fill = factor(Response))) + geom_bar(position = "dodge") + labs(title = "Proposal Acceptance by Income Category", x = "Income Category", y = "Count", fill = "Proposal Response") + theme_minimal()
```
The graph appears consistent across the four classified income categories, with the majority of individuals falling into the Low-Income category.

Null Hypothesis: There is no statistically significant difference in the Proposal Response based on an Individual's Income.
Alternative Hypothesis: There is a statistically significant difference in the Proposal Response based on an Individual's Income.

```{r}
# Contingency table for Income Category and Proposal Response
contingency_table <- table(cut(proposal_df$Income, 
                               breaks = c(5000, 20000, 30000, 40000, 50000), 
                               labels = c("Low Income", "Medium Income", "High Income", "Very High Income"), 
                               include.lowest = TRUE), 
                           proposal_df$Response)

# Chi-Square Test
chi_square_test <- chisq.test(contingency_table)
chi_square_test
```

The P-value is greater than significance level(0.05). Therefore, we cannot reject the Null Hypothesis. There is no statistically significant difference in the Proposal Response based on an Individual's Income.

### 4.2: Can a linear regression model effectively predict the Income of an individual using Age, Height, and RomanticGestureScore as predictors?

```{r}
# linear regression model
model_lr <- lm(Income ~ Age + Height + RomanticGestureScore, data = proposal_df)

# Summary of the model
summary(model_lr)
```

```{r}
# R-squared value
rsq <- summary(model_lr)$r.squared
cat("R-squared:", rsq, "\n")

# Mean Squared Error (MSE)
mse <- mean(residuals(model_lr)^2)
cat("Mean Squared Error:", mse, "\n")
```

```{r}
# Plot diagnostic plots
par(mfrow = c(2, 2))
plot(model_lr)
```

We will now try to predict income of an individual who are 30 years old and 160 cm tall with a score of 8 for Romantic Gesture.

```{r}
# Sample input data 
input1 <- data.frame(Age = 30, Height = 160, RomanticGestureScore = factor(8, levels = levels(proposal_df$RomanticGestureScore)))

#Prediction
predict1 <- predict(model_lr, newdata = input1)
predict1
```
The Linear Regression Model has predicted the income of such individual mentioned above to be $26637.

### 4.3: Which classification model (logistic regression, decision tree, or random forest) is the most suitable for predicting whether a proposal will be accepted or rejected based on Relational(RomanticGestureScore, CompatibilityScore, and DistanceKM) features? 

#### Logistic Regression Model
```{r, warning=FALSE}
# Split the dataset into training and testing sets 
set.seed(123)  
index <- createDataPartition(proposal_df$Response, p = 0.8, list = FALSE)
train_data <- proposal_df[index, ]
test_data <- proposal_df[-index, ]

# Logistic Regression Model
logistic_model <- glm(Response ~ RomanticGestureScore + CompatibilityScore + CommunicationScore, data = train_data, family = binomial)
logistic_probabilities <- predict(logistic_model, test_data, type = "response")
logistic_predicted <- ifelse(logistic_probabilities > 0.5, 1, 0)
actual <- as.factor(test_data$Response)
predicted <- as.factor(logistic_predicted)

# Confusion Matrix and metrics
confusion <- confusionMatrix(predicted, actual, positive = "1")
accuracy <- confusion$overall["Accuracy"]
precision <- confusion$byClass["Pos Pred Value"]  
recall <- confusion$byClass["Sensitivity"]       
f1_score <- 2 * (precision * recall) / (precision + recall)
# AUC
roc_curve <- roc(actual, logistic_probabilities, levels = c("0", "1"))
auc_value <- auc(roc_curve)

# Print metrics
cat("Logistic Regression Performance Metrics:\n")
cat("Accuracy: ", accuracy, "\n")
cat("Precision: ", precision, "\n")
cat("Recall: ", recall, "\n")
cat("F1-Score: ", f1_score, "\n")
cat("AUC: ", auc_value, "\n")

# Plot ROC Curve 
plot(roc_curve, main = "ROC Curve for Logistic Regression", col = "blue", lwd = 2)
abline(a = 0, b = 1, col = "gray", lty = 2)
auc_text <- paste("AUC =", round(auc_value, 3)) # Add AUC value to the plot
text(0.6, 0.2, auc_text, col = "blue", cex = 1.2)
```
#### Desicion Tree Model

```{r, warning=FALSE}

# Split the dataset into training and testing sets 
set.seed(123)
trainIndex <- createDataPartition(proposal_df$Response, p = 0.8, list = FALSE)
trainData <- proposal_df[trainIndex, ]
testData <- proposal_df[-trainIndex, ]

# Decision Tree Model
decision_tree_model <- rpart(Response ~ RomanticGestureScore + CompatibilityScore + CommunicationScore, data = trainData, method = "class")
predicted_probabilities_tree <- predict(decision_tree_model, proposal_df, type = "prob")[, 2]  
predicted_classes_tree <- predict(decision_tree_model, proposal_df, type = "class")            
actual <- as.factor(proposal_df$Response)

# Visualize the Decision Tree
rpart.plot(decision_tree_model, type = 2, extra = 104, main = "Decision Tree")

# Confusion Matrix and metrics
confusion_tree <- confusionMatrix(as.factor(predicted_classes_tree), actual, positive = "1")
accuracy_tree <- confusion_tree$overall["Accuracy"]
precision_tree <- confusion_tree$byClass["Pos Pred Value"]  
recall_tree <- confusion_tree$byClass["Sensitivity"]        
f1_score_tree <- 2 * (precision_tree * recall_tree) / (precision_tree + recall_tree)
roc_curve_tree <- roc(actual, predicted_probabilities_tree, levels = c("0", "1"))
auc_value_tree <- auc(roc_curve_tree)

# Print Metrics
cat("Decision Tree Metrics:\n")
cat("Accuracy:", round(accuracy_tree, 3), "\n")
cat("Precision:", round(precision_tree, 3), "\n")
cat("Recall:", round(recall_tree, 3), "\n")
cat("F1-Score:", round(f1_score_tree, 3), "\n")
cat("AUC:", round(auc_value_tree, 3), "\n")

# Plot ROC Curve 
plot(roc_curve_tree, main = "ROC Curve for Decision Tree", col = "blue", lwd = 2)
abline(a = 0, b = 1, col = "gray", lty = 2)
auc_text_tree <- paste("AUC =", round(auc_value_tree, 3)) # Add AUC value to the plot
text(0.6, 0.2, auc_text_tree, col = "blue", cex = 1.2)

```
#### Random Forest Model
```{r, echo=FALSE,  warning=FALSE}

# Split the dataset into training and testing sets 
set.seed(123)
trainIndex <- createDataPartition(proposal_df$Response, p = 0.8, list = FALSE)
trainData <- proposal_df[trainIndex, ]
testData <- proposal_df[-trainIndex, ]

# Random Forest Model
random_forest_model <- randomForest(Response ~ RomanticGestureScore + CompatibilityScore + CommunicationScore, data = trainData, ntree = 500, mtry = 2, importance = TRUE)

# Print model summary
# print(random_forest_model)

# Predictions
predicted_probabilities_rf <- predict(random_forest_model, proposal_df, type = "prob")[, 2]  # Probabilities for class 1
predicted_classes_rf <- predict(random_forest_model, proposal_df, type = "response")         # Predicted classes
actual <- as.factor(proposal_df$Response)

# Confusion Matrix and metrics
confusion_rf <- confusionMatrix(as.factor(predicted_classes_rf), actual, positive = "1")
accuracy_rf <- confusion_rf$overall["Accuracy"]
precision_rf <- confusion_rf$byClass["Pos Pred Value"]  
recall_rf <- confusion_rf$byClass["Sensitivity"]        
f1_score_rf <- 2 * (precision_rf * recall_rf) / (precision_rf + recall_rf)
roc_curve_rf <- roc(actual, predicted_probabilities_rf, levels = c("0", "1"))
auc_value_rf <- auc(roc_curve_rf)

# Print Metrics
cat("Random Forest Metrics:\n")
cat("Accuracy:", round(accuracy_rf, 3), "\n")
cat("Precision:", round(precision_rf, 3), "\n")
cat("Recall:", round(recall_rf, 3), "\n")
cat("F1-Score:", round(f1_score_rf, 3), "\n")
cat("AUC:", round(auc_value_rf, 3), "\n")

# Plot ROC Curve 
plot(roc_curve_rf, main = "ROC Curve for Random Forest", col = "blue", lwd = 2)
abline(a = 0, b = 1, col = "gray", lty = 2)
auc_text_rf <- paste("AUC =", round(auc_value_rf, 3)) # Add AUC value to the plot
text(0.6, 0.2, auc_text_rf, col = "blue", cex = 1.2)

# Variable Importance Plot
varImpPlot(random_forest_model, main = "Variable Importance - Random Forest")

```

### 4.4: How can we enhance the accuracy of a Random Forest model in predicting proposal acceptance using features like Income, Age, and DistanceKM? Adding/Dropping what other features might further improve the model's performance, and how would the model's accuracy change as a result?

```{r}
# Split the dataset into training and testing sets 

set.seed(123)
trainIndex <- createDataPartition(proposal_df$Response, p = 0.8, list = FALSE)
trainData <- proposal_df[trainIndex, ]
testData <- proposal_df[-trainIndex, ]

# Random Forest Model
random_forest_model <- randomForest(Response ~ Height + Income + Age + DistanceKM, data = trainData, ntree = 500, mtry = 2, importance = TRUE)
print(random_forest_model)
predicted_probabilities_rf <- predict(random_forest_model, proposal_df, type = "prob")[, 2]  # Probabilities for class 1
predicted_classes_rf <- predict(random_forest_model, proposal_df, type = "response")# Predicted classes
actual <- as.factor(proposal_df$Response)

# Confusion Matrix and metrics
confusion_rf <- confusionMatrix(as.factor(predicted_classes_rf), actual, positive = "1")
accuracy_rf <- confusion_rf$overall["Accuracy"]
precision_rf <- confusion_rf$byClass["Pos Pred Value"]  
recall_rf <- confusion_rf$byClass["Sensitivity"]        
f1_score_rf <- 2 * (precision_rf * recall_rf) / (precision_rf + recall_rf)
roc_curve_rf <- roc(actual, predicted_probabilities_rf, levels = c("0", "1"))
auc_value_rf <- auc(roc_curve_rf)


# Print Metrics
cat("Random Forest Metrics:\n")
cat("Accuracy:", round(accuracy_rf, 3), "\n")
cat("Precision:", round(precision_rf, 3), "\n")
cat("Recall:", round(recall_rf, 3), "\n")
cat("F1-Score:", round(f1_score_rf, 3), "\n")
cat("AUC:", round(auc_value_rf, 3), "\n")

# Plot ROC Curve
plot(roc_curve_rf, main = "ROC Curve for Random Forest", col = "blue", lwd = 2)
abline(a = 0, b = 1, col = "gray", lty = 2)
auc_text_rf <- paste("AUC =", round(auc_value_rf, 3)) # Add AUC value to the plot
text(0.6, 0.2, auc_text_rf, col = "blue", cex = 1.2)

# Variable Importance Plot
varImpPlot(random_forest_model, main = "Variable Importance - Random Forest")
```

```{r}
```

```{r}
# Train a random forest model for comparision
rf_model <- randomForest(Response ~ ., data = proposal_df)

# View feature importance
importance(rf_model)
varImpPlot(rf_model) # Plot
```

```{r}
# Updated Model

set.seed(123)
trainIndex <- createDataPartition(proposal_df$Response, p = 0.8, list = FALSE)
trainData <- proposal_df[trainIndex, ]
testData <- proposal_df[-trainIndex, ]

# Random Forest Model
random_forest_model <- randomForest(Response ~ Height + Income + Age + DistanceKM + CompatibilityScore + RomanticGestureScore, data = trainData, ntree = 500, mtry = 2, importance = TRUE)
print(random_forest_model)
predicted_probabilities_rf <- predict(random_forest_model, proposal_df, type = "prob")[, 2]  
predicted_classes_rf <- predict(random_forest_model, proposal_df, type = "response")
actual <- as.factor(proposal_df$Response)

# Confusion Matrix and metrics
confusion_rf <- confusionMatrix(as.factor(predicted_classes_rf), actual, positive = "1")
accuracy_rf <- confusion_rf$overall["Accuracy"]
precision_rf <- confusion_rf$byClass["Pos Pred Value"]  
recall_rf <- confusion_rf$byClass["Sensitivity"]        
f1_score_rf <- 2 * (precision_rf * recall_rf) / (precision_rf + recall_rf)
roc_curve_rf <- roc(actual, predicted_probabilities_rf, levels = c("0", "1"))
auc_value_rf <- auc(roc_curve_rf)

# Print Metrics
cat("Random Forest Metrics:\n")
cat("Accuracy:", round(accuracy_rf, 3), "\n")
cat("Precision:", round(precision_rf, 3), "\n")
cat("Recall:", round(recall_rf, 3), "\n")
cat("F1-Score:", round(f1_score_rf, 3), "\n")
cat("AUC:", round(auc_value_rf, 3), "\n")

# Plot ROC Curve
plot(roc_curve_rf, main = "ROC Curve for Random Forest", col = "blue", lwd = 2)
abline(a = 0, b = 1, col = "gray", lty = 2)
auc_text_rf <- paste("AUC =", round(auc_value_rf, 3)) 
text(0.6, 0.2, auc_text_rf, col = "blue", cex = 1.2)

# Variable Importance Plot
varImpPlot(random_forest_model, main = "Variable Importance - Random Forest")
```

```{r}
# Prediction model 
subject <- data.frame(
  RomanticGestureScore = factor(10, levels = levels(proposal_df$RomanticGestureScore)), CompatibilityScore = factor(7, levels = levels(proposal_df$CompatibilityScore)), DistanceKM = 10, Height = 169, Income = 6000, Age = 23)

predicted_classes <- predict(random_forest_model, subject, type = "response")

predicted_probabilities <- predict(random_forest_model, subject, type = "prob")

cat("Predicted Class (0 or 1):\n")
print(predicted_classes)
```
