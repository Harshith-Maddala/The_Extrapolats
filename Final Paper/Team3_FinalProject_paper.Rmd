---
title: "PREDICTING THE PROPOSAL: A Data-Driven Approach to Love"
author: "The Extrapolats"
date: "`r Sys.Date()`"
output:  
    rmdformats::readthedown:
      toc_float: true
      toc_depth: 3
      number_sections: false
      code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = F, results = "show", message = F)
library(ezids)
```

# ABSTRACT
```{r}
```

# INTRODUCTION
```{r}
```

# SUMMARY OF THE DATASET
```{r}
```

# DATASET OVERVIEW
```{r}
```

## Loading the Dataset 
```{r}
```

### Before Cleaning
```{r}
```

# DATA CLEANING

```{r}

# Check for empty and NA values 
empty_values <- sapply(proposal_df, function(x) sum(x == "", na.rm = TRUE))
na_values <- sapply(proposal_df, function(x) sum(is.na(x)))
print("Empty Values in Each Column:")
print(empty_values)
print("NA Values in Each Column:")
print(na_values)

```

```{r}

# Converting required 'int' columns into 'factor'
proposal_df$RomanticGestureScore <- as.factor(proposal_df$RomanticGestureScore)
proposal_df$CompatibilityScore <- as.factor(proposal_df$CompatibilityScore)
proposal_df$CommunicationScore <- as.factor(proposal_df$CommunicationScore)
proposal_df$Response <- as.factor(proposal_df$Response)

```



## Summary of the cleaned Dataset

```{r}

print("Summary of cleaned data")
summary(proposal_df)

```

# EXPLORATORY DATA ANALYSIS
### Loading necessary libraries

```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(psych)
library(tidyverse) 
library(ggplot2) 
library(viridis) 
library(RColorBrewer) 
library(ggmosaic)

library(gridExtra)
library(caret)
library(pROC)
library(rpart)
library(rpart.plot)
library(randomForest)
```


### Distribution of the Numeric variables

Let’s take a look at descriptive stats of Numeric variables.
```{r}
# Descriptive Statistics
# Numeric variables
describe(proposal_df %>% select(Age, Height, Income, DistanceKM))
```

Graphical Representations of Integer variables.

```{r}
# Histogram of age

ggplot(proposal_df, aes(x = Age, fill = Age)) + geom_histogram(binwidth = 5, fill = "lightpink", color = "black") + labs(title = "Age Distribution", x = "Age", y = "Frequency") + theme_minimal()
```

```{r, warning=FALSE}
# Frequency polygon for Height
ggplot(proposal_df, aes(x = Height)) + 
  geom_freqpoly(binwidth = 5, color = "grey", size = 1.2) + 
  labs(title = "Height Distribution", x = "Height (cm)", y = "Frequency") + 
  theme_minimal()

```


```{r}
# We can use this function to check if any outliers were detected in variables.
#proposal_df <- outlierKD2(proposal_df, DistanceKM, rm = TRUE, boxplt = TRUE, histogram = FALSE, qqplt = TRUE)
```

```{r}
ggplot(proposal_df, aes(x = cut(Income, breaks = c(5000, 20000, 30000, 40000, 50000), labels = c("Low Income", "Medium Income", "High Income", "Very High Income"), include.lowest = TRUE))) + geom_bar(fill = "steelblue", color = "black") + labs(title = "Population Distribution by Income Category", x = "Income Category", y = "Frequency") + theme_minimal()

```

```{r}
# Boxplot for Distance
ggplot(proposal_df, aes(y = DistanceKM)) + geom_boxplot(fill = "lightyellow", color = "black") + labs(title = "Distance (KM) Boxplot", y = "Distance (KM)") + theme_minimal()
```

Graphical Representations of Factorial variables.

```{r, warning=FALSE}
# Pie chart for Response variable
ggplot(proposal_df, aes(x = "", fill = Response)) + geom_bar(width = 1, stat = "count", color = "black") + coord_polar(theta = "y") + geom_text(aes(label = scales::percent(..count../sum(..count..))), position = position_stack(vjust = 0.5), stat = "count") + scale_fill_manual(values = c("0" = "red", "1" = "green"), labels = c("Rejected", "Accepted")) + labs(title = "Proposal Response Distribution", fill = "Response") + theme_void() + theme(plot.title = element_text(hjust = 0.5, size = 16))
```

```{r}
# bar plot for Communication Score
p1 <- ggplot(proposal_df, aes(x = as.factor(CommunicationScore))) + geom_bar(fill = "blue", color = "black") + labs(title = "Communication Score Distribution", x = "Communication Score", y = "Frequency") + theme_minimal()

# bar plot for Compatibility Score
p2 <- ggplot(proposal_df, aes(x = as.factor(CompatibilityScore))) + geom_bar(fill = "green", color = "black") + labs(title = "Compatibility Score Distribution", x = "Compatibility Score", y = "Frequency") + theme_minimal()

grid.arrange(p1, p2, ncol = 2)
```

The exploratory analysis showed low correlations among individual attributes such as Income, Age, and DistanceKM concerning proposal acceptance. We observed a minor rise in acceptance rates among higher-income groups, yet anomalies in Income and DistanceKM indicate that refining or modifying the data may improve model effectiveness. The distribution of Age indicated that younger individuals, particularly those aged 25–35, are more represented, with minor declines in acceptance rates in older groups. Distance played a critical role, with shorter distances correlating positively with acceptance, though its influence diminished significantly beyond 50 KM. Overall, the dataset lacked strong linear relationships, indicating that advanced feature engineering and interaction terms may be necessary to capture underlying patterns.

### Outlier removal
```{r}
```

# SMART QUESTIONS
```{r}
```

### Question 1:
```{r}
```

#### OBSERVATION:
```{r}
```

#### RESULT:
```{r}
```

### Question 2: Can a linear regression model effectively predict the Income of an individual using Age, Height, and RomanticGestureScore as predictors?

```{r}
# linear regression model
model_lr <- lm(Income ~ Age + Height + RomanticGestureScore, data = proposal_df)

# Summary of the model
summary(model_lr)

```

#### OBSERVATION:
```{r}
# R-squared value
rsq <- summary(model_lr)$r.squared
cat("R-squared:", rsq, "\n")
```

#### RESULT:
```{r}
```

### Question 3:
```{r}
```

#### OBSERVATION:
```{r}
```

#### RESULT:
```{r}
```

### Question 4: How can we enhance the accuracy of a Random Forest model in predicting proposal acceptance using features like Income, Age, and DistanceKM? Adding what other features might further improve the model's performance, and how would the model's accuracy change as a result?

# Split the dataset into training and testing sets 

set.seed(123)
trainIndex <- createDataPartition(proposal_df$Response, p = 0.8, list = FALSE)
trainData <- proposal_df[trainIndex, ]
testData <- proposal_df[-trainIndex, ]

# Random Forest Model
random_forest_model <- randomForest(Response ~ Height + Income + Age + DistanceKM, data = trainData, ntree = 500, mtry = 2, importance = TRUE)
print(random_forest_model)
predicted_probabilities_rf <- predict(random_forest_model, proposal_df, type = "prob")[, 2]  # Probabilities for class 1
predicted_classes_rf <- predict(random_forest_model, proposal_df, type = "response")# Predicted classes
actual <- as.factor(proposal_df$Response)

# Confusion Matrix and metrics
confusion_rf <- confusionMatrix(as.factor(predicted_classes_rf), actual, positive = "1")
accuracy_rf <- confusion_rf$overall["Accuracy"]
precision_rf <- confusion_rf$byClass["Pos Pred Value"]  
recall_rf <- confusion_rf$byClass["Sensitivity"]        
f1_score_rf <- 2 * (precision_rf * recall_rf) / (precision_rf + recall_rf)
roc_curve_rf <- roc(actual, predicted_probabilities_rf, levels = c("0", "1"))
auc_value_rf <- auc(roc_curve_rf)


# Print Metrics
cat("Random Forest Metrics:\n")
cat("Accuracy:", round(accuracy_rf, 3), "\n")
cat("Precision:", round(precision_rf, 3), "\n")
cat("Recall:", round(recall_rf, 3), "\n")
cat("F1-Score:", round(f1_score_rf, 3), "\n")
cat("AUC:", round(auc_value_rf, 3), "\n")

# Plot ROC Curve
plot(roc_curve_rf, main = "ROC Curve for Random Forest", col = "blue", lwd = 2)
abline(a = 0, b = 1, col = "gray", lty = 2)
auc_text_rf <- paste("AUC =", round(auc_value_rf, 3)) # Add AUC value to the plot
text(0.6, 0.2, auc_text_rf, col = "blue", cex = 1.2)

```

We consider all variables here to obtain the Mean Decrease Gini Scores of each variable

```{r}

# Train a random forest model for comparision
rf_model <- randomForest(Response ~ ., data = proposal_df)

# View feature importance
importance(rf_model)
varImpPlot(rf_model) # Plot

```

The Final Random Forest Model

```{r}
# Updated Model

set.seed(123)
trainIndex <- createDataPartition(proposal_df$Response, p = 0.8, list = FALSE)
trainData <- proposal_df[trainIndex, ]
testData <- proposal_df[-trainIndex, ]

# Random Forest Model
random_forest_model <- randomForest(Response ~ Height + Income + Age + DistanceKM + CompatibilityScore + RomanticGestureScore, data = trainData, ntree = 500, mtry = 2, importance = TRUE)
print(random_forest_model)
predicted_probabilities_rf <- predict(random_forest_model, proposal_df, type = "prob")[, 2]  
predicted_classes_rf <- predict(random_forest_model, proposal_df, type = "response")
actual <- as.factor(proposal_df$Response)

# Confusion Matrix and metrics
confusion_rf <- confusionMatrix(as.factor(predicted_classes_rf), actual, positive = "1")
accuracy_rf <- confusion_rf$overall["Accuracy"]
precision_rf <- confusion_rf$byClass["Pos Pred Value"]  
recall_rf <- confusion_rf$byClass["Sensitivity"]        
f1_score_rf <- 2 * (precision_rf * recall_rf) / (precision_rf + recall_rf)
roc_curve_rf <- roc(actual, predicted_probabilities_rf, levels = c("0", "1"))
auc_value_rf <- auc(roc_curve_rf)

# Print Metrics
cat("Random Forest Metrics:\n")
cat("Accuracy:", round(accuracy_rf, 3), "\n")
cat("Precision:", round(precision_rf, 3), "\n")
cat("Recall:", round(recall_rf, 3), "\n")
cat("F1-Score:", round(f1_score_rf, 3), "\n")
cat("AUC:", round(auc_value_rf, 3), "\n")

# Plot ROC Curve
plot(roc_curve_rf, main = "ROC Curve for Random Forest", col = "blue", lwd = 2)
abline(a = 0, b = 1, col = "gray", lty = 2)
auc_text_rf <- paste("AUC =", round(auc_value_rf, 3)) 
text(0.6, 0.2, auc_text_rf, col = "blue", cex = 1.2)

# Variable Importance Plot
varImpPlot(random_forest_model, main = "Variable Importance - Random Forest")

```

Let's consider an example and try to predict the Response for given values.

```{r}

# Prediction model
subject <- data.frame(
  RomanticGestureScore = factor(10, levels = levels(proposal_df$RomanticGestureScore)), CompatibilityScore = factor(7, levels = levels(proposal_df$CompatibilityScore)), DistanceKM = 10, Height = 169, Income = 6000, Age = 23)

predicted_classes <- predict(random_forest_model, subject, type = "response")

predicted_probabilities <- predict(random_forest_model, subject, type = "prob")

cat("Predicted Class (0 or 1):\n")
print(predicted_classes)

The Model Predicts the outcome to be 'Yes'(1).

#### OBSERVATION:

```{r}

According to the study, adding more features to a Random Forest model can improve its ability to predict proposal acceptance. Initially, the model included factors such as Height, Income, Age, and DistanceKM, which led to an Out-Of-Bag (OOB) error rate of 24.1%. Key performance metrics, including an accuracy of 95.1%, precision of 94.4%, recall of 99.5%, and an AUC of 0.97, showcased the model's strong predictive capabilities. Nevertheless, the Mean Decrease Gini scores indicated that factors such as CompatibilityScore and RomanticGestureScore were significantly important and could enhance predictions further. 

Integrating CompatibilityScore and RomanticGestureScore into the model resulted in significant enhancements. The ultimate Random Forest model reached a reduced OOB error rate of 22.5% and improved performance metrics, with accuracy rising to 95.9%, precision at 95.9%, recall at 98.9%, and an AUC of 0.984. These results emphasize the significance of incorporating highly pertinent features into the model, which more accurately represent the nuances of proposal approval. The updated feature set highlights the significant influence of CompatibilityScore, underlining that interpersonal compatibility plays a crucial role in predictions, offering important insights for further model enhancements.

```

#### RESULT:
```{r}
```

# CONCLUSION
```{r}
```

# REFERENCES
```{r}
```



